{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AmExpert Hackathon 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For reading columns with list\n",
    "from ast import literal_eval\n",
    "\n",
    "# For Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For Machine Learning Models\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# For Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('train_go05W65.csv',converters={'Product_Holding_B1': literal_eval,'Product_Holding_B2': literal_eval})\n",
    "test_original = pd.read_csv('test_VkM91FT.csv',converters={'Product_Holding_B1': literal_eval})\n",
    "\n",
    "# Making a copy of the datasets\n",
    "train = train_original.copy()\n",
    "test = test_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P16']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Product_Holding_B1'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test],axis = 0).reset_index(drop = True)\n",
    "df = pd.concat([train.assign(ind='train'),test.assign(ind='test'),], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58075 entries, 0 to 20326\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Customer_ID         58075 non-null  object\n",
      " 1   Gender              58075 non-null  object\n",
      " 2   Age                 58075 non-null  int64 \n",
      " 3   Vintage             58075 non-null  int64 \n",
      " 4   Is_Active           58075 non-null  int64 \n",
      " 5   City_Category       58075 non-null  object\n",
      " 6   Customer_Category   58075 non-null  object\n",
      " 7   Product_Holding_B1  58075 non-null  object\n",
      " 8   Product_Holding_B2  37748 non-null  object\n",
      " 9   ind                 58075 non-null  object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Is_Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58075.000000</td>\n",
       "      <td>58075.000000</td>\n",
       "      <td>58075.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.460146</td>\n",
       "      <td>19.585674</td>\n",
       "      <td>0.264572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.111050</td>\n",
       "      <td>10.252426</td>\n",
       "      <td>0.441109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age       Vintage     Is_Active\n",
       "count  58075.000000  58075.000000  58075.000000\n",
       "mean      38.460146     19.585674      0.264572\n",
       "std       10.111050     10.252426      0.441109\n",
       "min       24.000000      2.000000      0.000000\n",
       "25%       29.000000     13.000000      0.000000\n",
       "50%       37.000000     16.000000      0.000000\n",
       "75%       47.000000     23.000000      1.000000\n",
       "max       59.000000     80.000000      1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Customer_Category</th>\n",
       "      <th>Product_Holding_B1</th>\n",
       "      <th>Product_Holding_B2</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58075</td>\n",
       "      <td>58075</td>\n",
       "      <td>58075</td>\n",
       "      <td>58075</td>\n",
       "      <td>58075</td>\n",
       "      <td>37748</td>\n",
       "      <td>58075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>58075</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>738</td>\n",
       "      <td>495</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>CC264719</td>\n",
       "      <td>Male</td>\n",
       "      <td>C1</td>\n",
       "      <td>S3</td>\n",
       "      <td>[P13]</td>\n",
       "      <td>[P00]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>39757</td>\n",
       "      <td>29239</td>\n",
       "      <td>27474</td>\n",
       "      <td>11457</td>\n",
       "      <td>5908</td>\n",
       "      <td>37748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Customer_ID Gender City_Category Customer_Category Product_Holding_B1  \\\n",
       "count        58075  58075         58075             58075              58075   \n",
       "unique       58075      2             2                 3                738   \n",
       "top       CC264719   Male            C1                S3              [P13]   \n",
       "freq             1  39757         29239             27474              11457   \n",
       "\n",
       "       Product_Holding_B2    ind  \n",
       "count               37748  58075  \n",
       "unique                495      2  \n",
       "top                 [P00]  train  \n",
       "freq                 5908  37748  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58075 entries, 0 to 20326\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Customer_ID         58075 non-null  object\n",
      " 1   Gender              58075 non-null  object\n",
      " 2   Age                 58075 non-null  int64 \n",
      " 3   Vintage             58075 non-null  int64 \n",
      " 4   Is_Active           58075 non-null  int64 \n",
      " 5   City_Category       58075 non-null  object\n",
      " 6   Customer_Category   58075 non-null  object\n",
      " 7   Product_Holding_B1  58075 non-null  object\n",
      " 8   Product_Holding_B2  37748 non-null  object\n",
      " 9   ind                 58075 non-null  object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Value Imputation\n",
    "df['Product_Holding_B2'].fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating separate columns for each element of the list in the product holding columns and concatenating the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list in the column Product_Holding_B1 and Product_Holding_B1 is split into separate columns into a new dataframe. \n",
    "These two dataframes are then merged to the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phb1 = pd.DataFrame([{x: y for x, y in enumerate(item)} for item in df['Product_Holding_B1'].values.tolist()], index=df.index)\n",
    "df_phb1 = df_phb1.add_prefix('HB1_Product')\n",
    "\n",
    "df_phb2 = pd.DataFrame([{x: y for x, y in enumerate(item)} for item in df['Product_Holding_B2'].values.tolist()], index=df.index)\n",
    "df_phb2 = df_phb2.add_prefix('HB2_Product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58075 entries, 0 to 20326\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   HB2_Product0  58075 non-null  object\n",
      " 1   HB2_Product1  10171 non-null  object\n",
      " 2   HB2_Product2  3108 non-null   object\n",
      " 3   HB2_Product3  801 non-null    object\n",
      " 4   HB2_Product4  197 non-null    object\n",
      " 5   HB2_Product5  29 non-null     object\n",
      " 6   HB2_Product6  3 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_phb2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Joining  the dataframes to the train dataset\n",
    "concat_df = pd.concat([df, df_phb1,df_phb2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "concat_df.drop(['Product_Holding_B1','Product_Holding_B2'],inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID              0\n",
       "Gender                   0\n",
       "Age                      0\n",
       "Vintage                  0\n",
       "Is_Active                0\n",
       "City_Category            0\n",
       "Customer_Category        0\n",
       "ind                      0\n",
       "HB1_Product0             0\n",
       "HB1_Product1         30204\n",
       "HB1_Product2         49388\n",
       "HB1_Product3         55541\n",
       "HB1_Product4         57466\n",
       "HB1_Product5         57956\n",
       "HB1_Product6         58057\n",
       "HB1_Product7         58071\n",
       "HB2_Product0             0\n",
       "HB2_Product1         47904\n",
       "HB2_Product2         54967\n",
       "HB2_Product3         57274\n",
       "HB2_Product4         57878\n",
       "HB2_Product5         58046\n",
       "HB2_Product6         58072\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing null values for the entire dataset\n",
    "concat_df.fillna('N', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID          58075\n",
       "Gender                   2\n",
       "City_Category            2\n",
       "Customer_Category        3\n",
       "ind                      2\n",
       "HB1_Product0            22\n",
       "HB1_Product1            18\n",
       "HB1_Product2            15\n",
       "HB1_Product3            12\n",
       "HB1_Product4             9\n",
       "HB1_Product5             4\n",
       "HB1_Product6             3\n",
       "HB1_Product7             2\n",
       "HB2_Product0            20\n",
       "HB2_Product1            18\n",
       "HB2_Product2            16\n",
       "HB2_Product3            13\n",
       "HB2_Product4             9\n",
       "HB2_Product5             6\n",
       "HB2_Product6             3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.select_dtypes(include=['object']).T.apply(lambda x: x.nunique(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding nominal variables with few categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding nominal variables with few categories\n",
    "df_dm = pd.get_dummies(concat_df, columns= ['Gender','City_Category','Customer_Category'], prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding columns with high cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although LabelEncoder is used only for target variables, it is used here for User_ID column as other target encoders cannot be used. Target encoding will fail here as the target variable is multilabel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Encoding the User_ID column\n",
    "# Initialising the encoder\n",
    "le1 = LabelEncoder()\n",
    "\n",
    "## 1. Encoding Customer_ID Column\n",
    "df_le = df_dm\n",
    "\n",
    "df_le['Customer_ID'] = le1.fit_transform(df_le['Customer_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58075 entries, 0 to 20326\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Customer_ID           58075 non-null  int32 \n",
      " 1   Age                   58075 non-null  int64 \n",
      " 2   Vintage               58075 non-null  int64 \n",
      " 3   Is_Active             58075 non-null  int64 \n",
      " 4   ind                   58075 non-null  object\n",
      " 5   HB1_Product0          58075 non-null  object\n",
      " 6   HB1_Product1          58075 non-null  object\n",
      " 7   HB1_Product2          58075 non-null  object\n",
      " 8   HB1_Product3          58075 non-null  object\n",
      " 9   HB1_Product4          58075 non-null  object\n",
      " 10  HB1_Product5          58075 non-null  object\n",
      " 11  HB1_Product6          58075 non-null  object\n",
      " 12  HB1_Product7          58075 non-null  object\n",
      " 13  HB2_Product0          58075 non-null  object\n",
      " 14  HB2_Product1          58075 non-null  object\n",
      " 15  HB2_Product2          58075 non-null  object\n",
      " 16  HB2_Product3          58075 non-null  object\n",
      " 17  HB2_Product4          58075 non-null  object\n",
      " 18  HB2_Product5          58075 non-null  object\n",
      " 19  HB2_Product6          58075 non-null  object\n",
      " 20  Gender_Male           58075 non-null  uint8 \n",
      " 21  City_Category_C2      58075 non-null  uint8 \n",
      " 22  Customer_Category_S2  58075 non-null  uint8 \n",
      " 23  Customer_Category_S3  58075 non-null  uint8 \n",
      "dtypes: int32(1), int64(3), object(16), uint8(4)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_le.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N      47904\n",
       "P8      2560\n",
       "P12     2533\n",
       "P7      1051\n",
       "P10      936\n",
       "P6       784\n",
       "P4       528\n",
       "P5       448\n",
       "P9       434\n",
       "P3       344\n",
       "P13      261\n",
       "P16      178\n",
       "P11       68\n",
       "P14       13\n",
       "P2        11\n",
       "P15       11\n",
       "P17       10\n",
       "P18        1\n",
       "Name: HB2_Product1, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_le['HB2_Product1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Encoding the categorical columns derived from Product_Holding_B1 and Product_Holding_B2 columns\n",
    "\n",
    "# Initialising the encoder\n",
    "le2 = LabelEncoder()\n",
    "\n",
    "# Fitting the encoder to the column with highest number of classes\n",
    "df_le['HB1_Product0'] = le2.fit_transform(df_le['HB1_Product0'])\n",
    "\n",
    "# Creating a new dataframe to select list of object columns excluding 'ind'\n",
    "df_le2 = df_le\n",
    "df_le2 = df_le.drop('ind',axis = 1)\n",
    "object_cols = df_le2.select_dtypes(include=['object'])\n",
    "\n",
    "# Mapping unknown levels to the encoder\n",
    "df_le['HB1_Product1'] = df_le['HB1_Product1'].map(lambda s: 'N' if s not in le2.classes_ else s)\n",
    "le2.classes_ = np.append(le2.classes_, 'N')\n",
    "\n",
    "# Creating a new dataframe to select list of object columns excluding 'ind'\n",
    "df_le2 = df_le\n",
    "df_le2 = df_le.drop('ind',axis = 1)\n",
    "object_cols = df_le2.select_dtypes(include=['object'])\n",
    "\n",
    "# Transforming the rest of the object columns with the encoder\n",
    "for col in object_cols:\n",
    "    df_le[col] = le2.transform(df_le[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    20327\n",
       "20     7580\n",
       "0      5908\n",
       "4      4101\n",
       "18     3649\n",
       "1      3310\n",
       "8      3270\n",
       "16     2354\n",
       "15     2142\n",
       "2      1322\n",
       "5      1124\n",
       "21     1028\n",
       "19     1013\n",
       "17      616\n",
       "12      195\n",
       "3       111\n",
       "7        19\n",
       "13        4\n",
       "6         1\n",
       "9         1\n",
       "Name: HB2_Product0, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_le['HB2_Product0'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train = df_le[df_le['ind'].eq('test')], df_le[df_le['ind'].eq('train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37748 entries, 0 to 37747\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Customer_ID           37748 non-null  int32 \n",
      " 1   Age                   37748 non-null  int64 \n",
      " 2   Vintage               37748 non-null  int64 \n",
      " 3   Is_Active             37748 non-null  int64 \n",
      " 4   ind                   37748 non-null  object\n",
      " 5   HB1_Product0          37748 non-null  int32 \n",
      " 6   HB1_Product1          37748 non-null  int32 \n",
      " 7   HB1_Product2          37748 non-null  int32 \n",
      " 8   HB1_Product3          37748 non-null  int32 \n",
      " 9   HB1_Product4          37748 non-null  int32 \n",
      " 10  HB1_Product5          37748 non-null  int32 \n",
      " 11  HB1_Product6          37748 non-null  int32 \n",
      " 12  HB1_Product7          37748 non-null  int32 \n",
      " 13  HB2_Product0          37748 non-null  int32 \n",
      " 14  HB2_Product1          37748 non-null  int32 \n",
      " 15  HB2_Product2          37748 non-null  int32 \n",
      " 16  HB2_Product3          37748 non-null  int32 \n",
      " 17  HB2_Product4          37748 non-null  int32 \n",
      " 18  HB2_Product5          37748 non-null  int32 \n",
      " 19  HB2_Product6          37748 non-null  int32 \n",
      " 20  Gender_Male           37748 non-null  uint8 \n",
      " 21  City_Category_C2      37748 non-null  uint8 \n",
      " 22  Customer_Category_S2  37748 non-null  uint8 \n",
      " 23  Customer_Category_S3  37748 non-null  uint8 \n",
      "dtypes: int32(16), int64(3), object(1), uint8(4)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both columns Product_Holding_B1 and Product_Holding_B2, we can see instances of customers having upto 6 to 7 products. However, we will be predicting only the top 3 products for each customer. Hence, only the top 3 product columns for Holding_B1 and Holding_B2 are retained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retaining the top 3 products for Holding B1 and B2 and dropping the rest (Train dataset)\n",
    "X_train.drop(['HB1_Product3','HB1_Product4','HB1_Product5','HB1_Product6','HB1_Product7','HB2_Product3','HB2_Product4','HB2_Product5',\n",
    "'HB2_Product6','ind'], axis = 1, inplace = True)\n",
    "\n",
    "# Retaining the top 3 products for Holding B1 and dropping the rest (Test dataset)\n",
    "X_test.drop(['HB1_Product3','HB1_Product4','HB1_Product5','HB1_Product6','HB1_Product7','HB2_Product3','HB2_Product4','HB2_Product5',\n",
    "'HB2_Product6','HB2_Product0','HB2_Product1','HB2_Product2','ind'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Train dataset into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.drop(columns = ['HB2_Product0','HB2_Product1','HB2_Product2'], axis=1)\n",
    "y= X_train[['HB2_Product0','HB2_Product1','HB2_Product2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37748 entries, 0 to 37747\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   HB2_Product0  37748 non-null  int32\n",
      " 1   HB2_Product1  37748 non-null  int32\n",
      " 2   HB2_Product2  37748 non-null  int32\n",
      "dtypes: int32(3)\n",
      "memory usage: 737.3 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Evaluating the Machine Learning Models on the Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict values in a multilabel classification, MultiOutputClassifier is used. This will result in a 2D array as an output instead of 1D array in the usual classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy for Random Forest Classifier: 0.6184699977805052\n"
     ]
    }
   ],
   "source": [
    "# 3. Random Forest Classifier\n",
    "rf_model = MultiOutputClassifier(RandomForestClassifier())\n",
    "rf_score = cross_val_score(rf_model, X, y, cv=5)\n",
    "acc_rf = rf_score.mean()\n",
    "print(\" Accuracy for Random Forest Classifier:\", acc_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy for XGBoost Classifier: 0.6304176773556254\n"
     ]
    }
   ],
   "source": [
    "# 4. XGBoost Classifier\n",
    "xgb_model = MultiOutputClassifier(XGBClassifier(eval_metric='mlogloss'))\n",
    "xgb_score = cross_val_score(xgb_model, X, y, cv=5)\n",
    "acc_xgb = xgb_score.mean()\n",
    "print(\" Accuracy for XGBoost Classifier:\", acc_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Classifier has the highest accuracy of 0.63%. It is chosen as the final model to predict values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              eval_metric='mlogloss',\n",
       "                                              gamma=None, gpu_id=None,\n",
       "                                              importance_type='gain',\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, reg_alpha=None,\n",
       "                                              reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "xgb_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the value for the test dataset\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Inverse transforming the predicted values to get the original categories\n",
    "y_pred = le2.inverse_transform(y_pred.reshape(-1,1)).reshape(y_pred.shape)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['P10', 'N', 'N'],\n",
       "       ['P8', 'N', 'N'],\n",
       "       ['P16', 'N', 'N'],\n",
       "       ...,\n",
       "       ['P00', 'N', 'N'],\n",
       "       ['P1', 'P7', 'N'],\n",
       "       ['P1', 'P8', 'P8']], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 2d array into a dataframe with three columns\n",
    "predictions = pd.DataFrame(y_pred,columns = ['HB2_Product0','HB2_Product1','HB2_Product2'])\n",
    "\n",
    "# Converting 'N' (none) values into null values\n",
    "predictions = predictions.replace('N',np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the dataframe columns into a list\n",
    "\n",
    "def strip_strlist(list_to_strip):\n",
    "    return [item for item in list_to_strip if type(item) == str]\n",
    "\n",
    "# Converting the dataframe into a list\n",
    "pred = predictions.values.tolist()\n",
    "\n",
    "# Removing nulls from the list\n",
    "pred_dropna = [strip_strlist(list_entry) for list_entry in pred]\n",
    "\n",
    "# Map the values to a set\n",
    "pred_set = list(map(set, pred_dropna))\n",
    "\n",
    "# Convert the set to a list\n",
    "pred_list = list(map(list, pred_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Predicted Values to the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission1.csv')\n",
    "submission['Product_Holding_B2'] = pred_list\n",
    "submission.to_csv('sample_submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "505866359e0f6abc80a23237ac82fe3c3ff13ad56ef1bc291f0986fbf61cc3cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
